语音识别技术
[总结分析](http://tech.163.com/16/1226/17/C97THD0U00097U80.html)
[吴恩达ppt 2016](http://mt.sohu.com/20161207/n475237276.shtml)


百度，吴恩达： Deep Speech 短语词的措辞率降低到了3.7%
Google Speech API
wit.ai
bing speech
dictation

不久之前，百度又将 Deep CNN 应用于语音识别研究，使用了 VGGNet，以及包含 Residual 连接的深层 CNN 等结构，并将 LSTM 和 CTC 的端对端语音识别技术相结合，使得识别错误率相对下降了 10%（原错误率的 90%）以上。

技术提升基础：1. 端到端深度学习方法；2. 深层卷积神经网络技术（Deep CNN）应用于语音识别声学建模中，与基于长短时记忆单元（LSTM）和连接时序分类（CTC）的端对端语音识别技术相结合。
2.IBM Watson 会话词错率低至 6.9%
=============================================

HTK 和 Kaldi

在这一部分我简单的梳理了一下语音识别历史上比较关键的一些时间点，至于详细的语音识别技术研究历史可参考之前提到的黄学东老师写的《四十年的难题与荣耀——从历史视角看语音识别发展》。
1952 年，贝尔实验室 Davis 等人研制了世界上第一个能识别 10 个英文数字发音的实验系统，但只能识别一人的发音。
1962 年，IBM 展示了 Shoebox。Shoebox 能理解 16 个口语单词以及 0-9 的英文数字。
1969 年，贝尔实验室的 John Pierce 预言成熟的语音识别在数十年内不会成为现实，因为它需要人工智能。
1970 年，普林斯顿大学的 Lenny Baum 发明隐马尔可夫模型（Hidden Markov Model)。
20 世纪 70 年代，卡耐基梅隆大学研发 harpy speech recognition system，能够识别 1011 个单词，相当于 3 岁儿童的词汇量。
20 世纪 80 年代，语音识别引入了隐马尔可夫模型（Hidden Markov Model)。
20 世纪 90 年代出现首个消费级产品 DragonDictate，由国际语音识别公司 Nuance 发布。
2007 年，Dag Kittlaus 和 Adam Cheyer 创立 Siri.Inc。后被苹果收购并于 2011 年首次出现在 iPhone 4s 上。
2009 年以来，借助机器学习领域深度学习研究的发展以及大数据语料的积累，语音识别技术得到突飞猛进的发展。
2011 年微软率先取得突破，使用深度神经网络模型之后，语音识别错误率降低 30%。
2015 年，IBM Watson 公布了英语会话语音识别领域的一个重大里程碑：系统在非常流行的评测基准 Switchboard 数据库中取得了 8% 的词错率（WER）。
语音识别，在这一年有了极大的发展，从算法到模型都有了质的变化，在加上语音领域（语音合成等）的其他研究，语音技术陆续进入工业、家庭机器人、通信、车载导航等各个领域中。当有一天，机器能够真正「理解」人类语言，并作出回应，那时我们必将迎来一个崭新的时代。
